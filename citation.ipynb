{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "citation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZECBpTKulskT"
      },
      "source": [
        "Name:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZQURFk6WsgT",
        "outputId": "7adbe458-c68b-4521-8730-6c71f4580438"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmpvFq9NahJ3"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov7317d8axoS"
      },
      "source": [
        "CORA='/content/gdrive/MyDrive/CORA/'\n",
        "\n",
        "with open(CORA + 'vocab-lower.pickle', 'rb') as f:\n",
        "    #vocab dic is list of all words in the dictionery\n",
        "    vocab_dic = list(map(lambda x: x.decode('utf-8'), pickle.load(f, encoding='utf-8')))\n",
        "\n",
        "\n",
        "with open(CORA + 'vocab_labels.pickle', 'rb') as f:\n",
        "    #The list of possible labels \n",
        "    label_dic = list(map(lambda x: x.decode('utf-8'), pickle.load(f, encoding='bytes')))\n",
        "    \n",
        "with open(CORA + 'trained_embedding.pickle', 'rb') as f:\n",
        "    #The trained embedding on Wikipedia using GLOVE algorithm \n",
        "    #Each column is the embedding of a word (with respect to the vocab dictionary) \n",
        "    embedding = pickle.load(f, encoding='bytes')\n",
        "    vocabulary_size = 20608\n",
        "    embedding_size = 100\n",
        "\n",
        "\n",
        "with open(CORA + 'xdata-lower.pickle', 'rb') as f:\n",
        "    #Each row is a citation. Each cell is the token id (with respect to the vocab dictionary) within the citation.\n",
        "    xdata = pickle.load(f, encoding='bytes')\n",
        "\n",
        "with open(CORA + 'Y_train.pickle', 'rb') as f:\n",
        "    ydata = pickle.load(f, encoding='bytes')\n",
        "\n",
        "with open(CORA + 'xval-lower.pickle', 'rb') as f:\n",
        "    xval = pickle.load(f, encoding='bytes')\n",
        "\n",
        "with open(CORA + 'Y_dev.pickle', 'rb') as f:\n",
        "    yval = pickle.load(f, encoding='bytes')\n",
        "\n",
        "with open(CORA + 'xtest-lower.pickle', 'rb') as f:\n",
        "    xtest = pickle.load(f, encoding='bytes')\n",
        "\n",
        "with open(CORA + 'Y_test.pickle', 'rb') as f:\n",
        "    ytest = pickle.load(f, encoding='bytes')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTXl5Ob2bQtC",
        "outputId": "80dc23a6-7803-4e40-8fd3-bc61761ba976"
      },
      "source": [
        "\n",
        "print(\"vocab size:\", len(vocab_dic))\n",
        "print(vocab_dic[100], vocab_dic[200])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 18049\n",
            "no formal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z09S8ClbVvw"
      },
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "  norm_v1 = np.linalg.norm(v1)\n",
        "  norm_v2 = np.linalg.norm(v2)\n",
        "  return np.dot(v1,v2)/(norm_v1*norm_v2)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGKg5ll-cU4O"
      },
      "source": [
        "v1_id = vocab_dic.index('positive')\n",
        "v2_id = vocab_dic.index('constructive')\n",
        "v3_id = vocab_dic.index('conference')\n",
        "\n",
        "v1_vec = embedding[v1_id]\n",
        "v2_vec = embedding[v2_id]\n",
        "v3_vec = embedding[v3_id]\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmLEhiIxc7FO",
        "outputId": "ea4aed65-bd99-4176-b763-70fde795ef75"
      },
      "source": [
        "cosine_similarity(v1_vec,v2_vec)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40829688468111025"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx5u_An5eMTp",
        "outputId": "e8634789-db63-40c1-dc2e-2877f9d7fdae"
      },
      "source": [
        "cosine_similarity(v1_vec, v3_vec)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.226298426910638"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnxWHKR0ePbV",
        "outputId": "a2887935-e503-4915-e2d3-9e43fd1583aa"
      },
      "source": [
        "#construct the sentence\n",
        "print(xdata[1])\n",
        "#each cell is the token id and 0 means padding.\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   16     1  4426     2    33     1  2014     2     4    38     1  8853\n",
            "     3 14152     1   189     5  1901    37    59   839   128     4   319\n",
            "   155     1   102   282    62     2    46     7    46     8     2   297\n",
            "     1     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPfk5QVjebKo"
      },
      "source": [
        "def get_sentence(x):\n",
        "  x_nopad = list(filter(lambda i: True if i > 0 else False, x))\n",
        "  return ' '.join([vocab_dic[id] for id in x_nopad])\n",
        "\n",
        "def get_label(y):\n",
        "  y_nopad = list(filter(lambda i: True if i > 0 else False, y))\n",
        "  return ' '.join([label_dic[id] for id in y_nopad])\n",
        "\n",
        "def print_sentence_label_pair(x, y):\n",
        "  x_nopad = list(filter(lambda i: True if i > 0 else False, x))\n",
        "  y_nopad = list(filter(lambda i: True if i > 0 else False, y))\n",
        "  for i in range(len(x_nopad)):\n",
        "    print(label_dic[y_nopad[i]],'\\t\\t' ,vocab_dic[x_nopad[i]],)\n",
        "\n",
        "def print_sentence_pred_label(x, y, yt):\n",
        "  x_nopad = list(filter(lambda i: True if i > 0 else False, x))\n",
        "  for i in range(len(x_nopad)):\n",
        "    print(label_dic[yt[i]], label_dic[y[i]],'\\t\\t'  ,vocab_dic[x_nopad[i]],)\n"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl8DO5jJgB68",
        "outputId": "7f4503b6-bca9-478a-c9f4-204e6d51a69e"
      },
      "source": [
        "print_sentence_label_pair(xdata[10], ydata[10])\n",
        "# print(get_sentence(xdata[10]))\n",
        "# print(get_label(ydata[10]))"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "author \t\t ramadge\n",
            "author \t\t ,\n",
            "author \t\t p\n",
            "author \t\t .\n",
            "author \t\t ,\n",
            "author \t\t &\n",
            "author \t\t wonham\n",
            "author \t\t ,\n",
            "author \t\t w\n",
            "author \t\t .\n",
            "date \t\t (\n",
            "date \t\t 1989\n",
            "date \t\t )\n",
            "date \t\t .\n",
            "title \t\t the\n",
            "title \t\t control\n",
            "title \t\t of\n",
            "title \t\t discrete\n",
            "title \t\t event\n",
            "title \t\t systems\n",
            "title \t\t .\n",
            "booktitle \t\t proceedings\n",
            "booktitle \t\t of\n",
            "booktitle \t\t the\n",
            "booktitle \t\t ieee\n",
            "booktitle \t\t ,\n",
            "volume \t\t 77\n",
            "volume \t\t (\n",
            "volume \t\t 1\n",
            "volume \t\t )\n",
            "volume \t\t ,\n",
            "pages \t\t 81\n",
            "pages \t\t -\n",
            "pages \t\t 98\n",
            "pages \t\t .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbU7C7R1RMb4"
      },
      "source": [
        "#calucate the hamming loss between gold data and predication\n",
        "def token_level_loss(cpred, ctrue):\n",
        "  try:\n",
        "    label_num = np.shape(cpred)[1]\n",
        "    pred = cpred.astype(np.int)\n",
        "    true = ctrue.astype(np.int)\n",
        "    n1 = len(pred)\n",
        "    n2 = len(true)\n",
        "    assert n1 == n2\n",
        "    hloss = 0.0\n",
        "    exact_acc = 0.0\n",
        "    for i in range(n1):\n",
        "      sample_loss = 0.0\n",
        "      exact = 0.0\n",
        "      xp = pred[i]\n",
        "      xt = true[i]\n",
        "      cnp = 0\n",
        "      for j in range(label_num):\n",
        "        if (xt[j] == 0):\n",
        "          continue\n",
        "        cnp+=1\n",
        "        if xp[j] != xt[j]:\n",
        "          sample_loss += 1.0\n",
        "        else:\n",
        "          exact +=1\n",
        "      sample_loss = sample_loss / cnp\n",
        "      exact = exact / cnp\n",
        "      hloss += sample_loss\n",
        "      exact_acc += exact\n",
        "    return (hloss / n1, exact_acc / n1)\n",
        "  except Warning:\n",
        "    return (0.0,0.0);\n",
        "\n",
        "def perf(ytr_pred, yval_pred, yts_pred, ydata, yval, ytest):\n",
        "    global best_val\n",
        "    global test_val\n",
        "\n",
        "    hm_ts, ex_ts = token_level_loss(yts_pred, ytest)\n",
        "    hm_tr, ex_tr = token_level_loss(ytr_pred, ydata)\n",
        "    hm_val, ex_val = token_level_loss(yval_pred, yval)\n",
        "    if ex_val > best_val:\n",
        "        best_val = ex_val\n",
        "        test_val = ex_ts\n",
        "    return (\"Train: %0.3f Val: %0.3f Test: %0.3f -- Best Val: %0.3f Test: %0.3f\" % (ex_tr, ex_val, ex_ts, best_val, test_val))"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSRNVhcugZZv"
      },
      "source": [
        "output_size = len(label_dic)\n",
        "max_length_output = 118\n",
        "class CitationNetwork(tf.keras.Model):\n",
        "  def __init__(self, network_type = 'SimpleLSTM'):\n",
        "      super(CitationNetwork, self).__init__()\n",
        "\n",
        "      self.optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "      self.embedding = layers.Embedding(input_dim=vocabulary_size, output_dim=embedding_size)\n",
        "      self.rnn = layers.LSTM(128, return_sequences=True, return_state=True)\n",
        "\n",
        "      self.fc = layers.Dense(output_size)\n",
        "  \n",
        " \n",
        "  def call(self, x, predict=True):\n",
        "      emb = self.embedding(x)\n",
        "      output, _ , _ = self.rnn(emb)\n",
        "      output = self.fc(output)\n",
        "      if predict:\n",
        "        return tf.math.argmax(output, axis=-1)\n",
        "      return output\n",
        "  \n",
        "  def get_loss(self, ylogits, yt):\n",
        "    ylabels = tf.one_hot(ybatch, output_size)\n",
        "    cross_ent = tf.nn.softmax_cross_entropy_with_logits(logits=ylogits, labels=ylabels);\n",
        "    return tf.reduce_sum(cross_ent)\n",
        "\n",
        "@tf.function\n",
        "def train_step(xbatch, ybatch):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        prediction = cite(xbatch, False)\n",
        "        loss = cite.get_loss(prediction, ybatch)\n",
        "        \n",
        "    gradients = tape.gradient(loss, cite.trainable_variables)\n",
        "    cite.optimizer.apply_gradients(zip(gradients, cite.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "cite = CitationNetwork();\n",
        "\n",
        "        "
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_2HngfD8jrBE",
        "outputId": "aadc49dd-c132-46e5-b145-eadea2c78998"
      },
      "source": [
        "train_size = xdata.shape[0]\n",
        "batch_size = 10\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices(np.hstack((xdata, ydata)))\n",
        "                 .shuffle(train_size).batch(batch_size))\n",
        "# print(xdata.shape)\n",
        "num_epoch = 1000\n",
        "i = 0;\n",
        "best_val = 0\n",
        "test_val = 0\n",
        "\n",
        "while i < num_epoch:\n",
        "  loss = 0;\n",
        "  for batch in train_dataset:\n",
        "    xbatch = batch[:, :max_length_output]\n",
        "    ybatch = batch[:, max_length_output:]\n",
        "    loss += train_step(xbatch, ybatch)\n",
        "\n",
        "  ypred_test = cite(xtest, predict=True).numpy()\n",
        "  ypred_val = cite(xval, predict=True).numpy()\n",
        "  ypred_train = cite(xdata, predict=True).numpy()\n",
        "  print(i, loss.numpy(), perf(ypred_train, ypred_val, ypred_test, ydata, yval, ytest) )\n",
        "  i = i+1\n",
        "  # break"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 93806.17 Train: 0.104 Val: 0.108 Test: 0.112 -- Best Val: 0.108 Test: 0.112\n",
            "1 93276.89 Train: 0.109 Val: 0.112 Test: 0.119 -- Best Val: 0.112 Test: 0.119\n",
            "2 92731.08 Train: 0.108 Val: 0.111 Test: 0.120 -- Best Val: 0.112 Test: 0.119\n",
            "3 92155.65 Train: 0.103 Val: 0.103 Test: 0.114 -- Best Val: 0.112 Test: 0.119\n",
            "4 91520.74 Train: 0.084 Val: 0.088 Test: 0.097 -- Best Val: 0.112 Test: 0.119\n",
            "5 90792.98 Train: 0.060 Val: 0.066 Test: 0.069 -- Best Val: 0.112 Test: 0.119\n",
            "6 89926.64 Train: 0.039 Val: 0.040 Test: 0.049 -- Best Val: 0.112 Test: 0.119\n",
            "7 88854.76 Train: 0.025 Val: 0.023 Test: 0.027 -- Best Val: 0.112 Test: 0.119\n",
            "8 87374.99 Train: 0.015 Val: 0.016 Test: 0.015 -- Best Val: 0.112 Test: 0.119\n",
            "9 85164.234 Train: 0.007 Val: 0.009 Test: 0.008 -- Best Val: 0.112 Test: 0.119\n",
            "10 81209.71 Train: 0.004 Val: 0.006 Test: 0.005 -- Best Val: 0.112 Test: 0.119\n",
            "11 71110.586 Train: 0.002 Val: 0.002 Test: 0.002 -- Best Val: 0.112 Test: 0.119\n",
            "12 53208.266 Train: 0.001 Val: 0.002 Test: 0.001 -- Best Val: 0.112 Test: 0.119\n",
            "13 43619.52 Train: 0.001 Val: 0.002 Test: 0.001 -- Best Val: 0.112 Test: 0.119\n",
            "14 39432.03 Train: 0.001 Val: 0.002 Test: 0.001 -- Best Val: 0.112 Test: 0.119\n",
            "15 37720.83 Train: 0.001 Val: 0.002 Test: 0.001 -- Best Val: 0.112 Test: 0.119\n",
            "16 37221.164 Train: 0.001 Val: 0.002 Test: 0.001 -- Best Val: 0.112 Test: 0.119\n",
            "17 37105.766 Train: 0.001 Val: 0.003 Test: 0.001 -- Best Val: 0.112 Test: 0.119\n",
            "18 36913.453 Train: 0.001 Val: 0.003 Test: 0.001 -- Best Val: 0.112 Test: 0.119\n",
            "19 36832.066 Train: 0.001 Val: 0.003 Test: 0.001 -- Best Val: 0.112 Test: 0.119\n",
            "20 36755.2 Train: 0.002 Val: 0.003 Test: 0.002 -- Best Val: 0.112 Test: 0.119\n",
            "21 36798.87 Train: 0.002 Val: 0.003 Test: 0.002 -- Best Val: 0.112 Test: 0.119\n",
            "22 36692.75 Train: 0.002 Val: 0.003 Test: 0.002 -- Best Val: 0.112 Test: 0.119\n",
            "23 36689.832 Train: 0.002 Val: 0.003 Test: 0.002 -- Best Val: 0.112 Test: 0.119\n",
            "24 36506.234 Train: 0.003 Val: 0.003 Test: 0.003 -- Best Val: 0.112 Test: 0.119\n",
            "25 36380.707 Train: 0.003 Val: 0.003 Test: 0.003 -- Best Val: 0.112 Test: 0.119\n",
            "26 36486.203 Train: 0.003 Val: 0.004 Test: 0.003 -- Best Val: 0.112 Test: 0.119\n",
            "27 36348.93 Train: 0.003 Val: 0.004 Test: 0.003 -- Best Val: 0.112 Test: 0.119\n",
            "28 36309.8 Train: 0.003 Val: 0.004 Test: 0.004 -- Best Val: 0.112 Test: 0.119\n",
            "29 36164.297 Train: 0.003 Val: 0.004 Test: 0.005 -- Best Val: 0.112 Test: 0.119\n",
            "30 36134.477 Train: 0.004 Val: 0.005 Test: 0.005 -- Best Val: 0.112 Test: 0.119\n",
            "31 36188.24 Train: 0.004 Val: 0.005 Test: 0.005 -- Best Val: 0.112 Test: 0.119\n",
            "32 36280.645 Train: 0.004 Val: 0.006 Test: 0.006 -- Best Val: 0.112 Test: 0.119\n",
            "33 36137.867 Train: 0.005 Val: 0.006 Test: 0.006 -- Best Val: 0.112 Test: 0.119\n",
            "34 36087.402 Train: 0.005 Val: 0.007 Test: 0.007 -- Best Val: 0.112 Test: 0.119\n",
            "35 36111.17 Train: 0.005 Val: 0.007 Test: 0.007 -- Best Val: 0.112 Test: 0.119\n",
            "36 36324.53 Train: 0.006 Val: 0.007 Test: 0.009 -- Best Val: 0.112 Test: 0.119\n",
            "37 35958.258 Train: 0.007 Val: 0.011 Test: 0.009 -- Best Val: 0.112 Test: 0.119\n",
            "38 36025.836 Train: 0.008 Val: 0.011 Test: 0.010 -- Best Val: 0.112 Test: 0.119\n",
            "39 35998.688 Train: 0.010 Val: 0.013 Test: 0.011 -- Best Val: 0.112 Test: 0.119\n",
            "40 36065.465 Train: 0.012 Val: 0.013 Test: 0.013 -- Best Val: 0.112 Test: 0.119\n",
            "41 35895.184 Train: 0.013 Val: 0.018 Test: 0.015 -- Best Val: 0.112 Test: 0.119\n",
            "42 35852.027 Train: 0.016 Val: 0.021 Test: 0.019 -- Best Val: 0.112 Test: 0.119\n",
            "43 35992.508 Train: 0.017 Val: 0.022 Test: 0.019 -- Best Val: 0.112 Test: 0.119\n",
            "44 35829.45 Train: 0.019 Val: 0.024 Test: 0.020 -- Best Val: 0.112 Test: 0.119\n",
            "45 35791.17 Train: 0.020 Val: 0.025 Test: 0.021 -- Best Val: 0.112 Test: 0.119\n",
            "46 35802.617 Train: 0.021 Val: 0.025 Test: 0.022 -- Best Val: 0.112 Test: 0.119\n",
            "47 35734.84 Train: 0.021 Val: 0.026 Test: 0.023 -- Best Val: 0.112 Test: 0.119\n",
            "48 35535.4 Train: 0.023 Val: 0.027 Test: 0.025 -- Best Val: 0.112 Test: 0.119\n",
            "49 35493.15 Train: 0.024 Val: 0.028 Test: 0.026 -- Best Val: 0.112 Test: 0.119\n",
            "50 35546.305 Train: 0.025 Val: 0.028 Test: 0.027 -- Best Val: 0.112 Test: 0.119\n",
            "51 35648.07 Train: 0.026 Val: 0.028 Test: 0.028 -- Best Val: 0.112 Test: 0.119\n",
            "52 35407.875 Train: 0.029 Val: 0.031 Test: 0.030 -- Best Val: 0.112 Test: 0.119\n",
            "53 35455.59 Train: 0.031 Val: 0.033 Test: 0.031 -- Best Val: 0.112 Test: 0.119\n",
            "54 35472.83 Train: 0.032 Val: 0.036 Test: 0.034 -- Best Val: 0.112 Test: 0.119\n",
            "55 35544.613 Train: 0.036 Val: 0.037 Test: 0.037 -- Best Val: 0.112 Test: 0.119\n",
            "56 35389.973 Train: 0.038 Val: 0.040 Test: 0.038 -- Best Val: 0.112 Test: 0.119\n",
            "57 35355.33 Train: 0.042 Val: 0.045 Test: 0.041 -- Best Val: 0.112 Test: 0.119\n",
            "58 35317.438 Train: 0.045 Val: 0.046 Test: 0.045 -- Best Val: 0.112 Test: 0.119\n",
            "59 35315.793 Train: 0.046 Val: 0.047 Test: 0.048 -- Best Val: 0.112 Test: 0.119\n",
            "60 35321.9 Train: 0.049 Val: 0.048 Test: 0.050 -- Best Val: 0.112 Test: 0.119\n",
            "61 35313.52 Train: 0.051 Val: 0.051 Test: 0.052 -- Best Val: 0.112 Test: 0.119\n",
            "62 35161.402 Train: 0.055 Val: 0.055 Test: 0.056 -- Best Val: 0.112 Test: 0.119\n",
            "63 35165.098 Train: 0.058 Val: 0.058 Test: 0.058 -- Best Val: 0.112 Test: 0.119\n",
            "64 35268.78 Train: 0.061 Val: 0.060 Test: 0.060 -- Best Val: 0.112 Test: 0.119\n",
            "65 35117.51 Train: 0.065 Val: 0.065 Test: 0.064 -- Best Val: 0.112 Test: 0.119\n",
            "66 35148.86 Train: 0.068 Val: 0.069 Test: 0.067 -- Best Val: 0.112 Test: 0.119\n",
            "67 35098.855 Train: 0.072 Val: 0.072 Test: 0.071 -- Best Val: 0.112 Test: 0.119\n",
            "68 35011.258 Train: 0.075 Val: 0.073 Test: 0.073 -- Best Val: 0.112 Test: 0.119\n",
            "69 34992.42 Train: 0.079 Val: 0.075 Test: 0.076 -- Best Val: 0.112 Test: 0.119\n",
            "70 34894.992 Train: 0.082 Val: 0.080 Test: 0.080 -- Best Val: 0.112 Test: 0.119\n",
            "71 34844.844 Train: 0.085 Val: 0.083 Test: 0.084 -- Best Val: 0.112 Test: 0.119\n",
            "72 34900.3 Train: 0.089 Val: 0.085 Test: 0.088 -- Best Val: 0.112 Test: 0.119\n",
            "73 34888.68 Train: 0.092 Val: 0.087 Test: 0.089 -- Best Val: 0.112 Test: 0.119\n",
            "74 34861.402 Train: 0.096 Val: 0.090 Test: 0.092 -- Best Val: 0.112 Test: 0.119\n",
            "75 34743.81 Train: 0.099 Val: 0.092 Test: 0.095 -- Best Val: 0.112 Test: 0.119\n",
            "76 34772.867 Train: 0.102 Val: 0.095 Test: 0.096 -- Best Val: 0.112 Test: 0.119\n",
            "77 34777.0 Train: 0.103 Val: 0.097 Test: 0.098 -- Best Val: 0.112 Test: 0.119\n",
            "78 34780.164 Train: 0.107 Val: 0.101 Test: 0.102 -- Best Val: 0.112 Test: 0.119\n",
            "79 34736.953 Train: 0.110 Val: 0.102 Test: 0.106 -- Best Val: 0.112 Test: 0.119\n",
            "80 34622.53 Train: 0.114 Val: 0.107 Test: 0.112 -- Best Val: 0.112 Test: 0.119\n",
            "81 34582.72 Train: 0.118 Val: 0.109 Test: 0.114 -- Best Val: 0.112 Test: 0.119\n",
            "82 34571.758 Train: 0.120 Val: 0.112 Test: 0.118 -- Best Val: 0.112 Test: 0.119\n",
            "83 34581.285 Train: 0.123 Val: 0.115 Test: 0.122 -- Best Val: 0.115 Test: 0.122\n",
            "84 34492.645 Train: 0.128 Val: 0.119 Test: 0.126 -- Best Val: 0.119 Test: 0.126\n",
            "85 34554.33 Train: 0.131 Val: 0.127 Test: 0.132 -- Best Val: 0.127 Test: 0.132\n",
            "86 34354.086 Train: 0.136 Val: 0.130 Test: 0.137 -- Best Val: 0.130 Test: 0.137\n",
            "87 34391.426 Train: 0.139 Val: 0.133 Test: 0.140 -- Best Val: 0.133 Test: 0.140\n",
            "88 34316.36 Train: 0.145 Val: 0.139 Test: 0.147 -- Best Val: 0.139 Test: 0.147\n",
            "89 34295.035 Train: 0.149 Val: 0.144 Test: 0.152 -- Best Val: 0.144 Test: 0.152\n",
            "90 34252.285 Train: 0.153 Val: 0.147 Test: 0.157 -- Best Val: 0.147 Test: 0.157\n",
            "91 34153.363 Train: 0.159 Val: 0.152 Test: 0.165 -- Best Val: 0.152 Test: 0.165\n",
            "92 34223.793 Train: 0.164 Val: 0.157 Test: 0.173 -- Best Val: 0.157 Test: 0.173\n",
            "93 34121.92 Train: 0.169 Val: 0.163 Test: 0.179 -- Best Val: 0.163 Test: 0.179\n",
            "94 34088.195 Train: 0.178 Val: 0.170 Test: 0.188 -- Best Val: 0.170 Test: 0.188\n",
            "95 33979.152 Train: 0.185 Val: 0.176 Test: 0.197 -- Best Val: 0.176 Test: 0.197\n",
            "96 33948.57 Train: 0.191 Val: 0.183 Test: 0.204 -- Best Val: 0.183 Test: 0.204\n",
            "97 33930.004 Train: 0.202 Val: 0.195 Test: 0.215 -- Best Val: 0.195 Test: 0.215\n",
            "98 33878.23 Train: 0.208 Val: 0.201 Test: 0.223 -- Best Val: 0.201 Test: 0.223\n",
            "99 33789.637 Train: 0.216 Val: 0.212 Test: 0.238 -- Best Val: 0.212 Test: 0.238\n",
            "100 33689.496 Train: 0.224 Val: 0.220 Test: 0.247 -- Best Val: 0.220 Test: 0.247\n",
            "101 33625.605 Train: 0.234 Val: 0.233 Test: 0.263 -- Best Val: 0.233 Test: 0.263\n",
            "102 33616.277 Train: 0.242 Val: 0.243 Test: 0.273 -- Best Val: 0.243 Test: 0.273\n",
            "103 33511.79 Train: 0.250 Val: 0.252 Test: 0.285 -- Best Val: 0.252 Test: 0.285\n",
            "104 33435.42 Train: 0.258 Val: 0.264 Test: 0.294 -- Best Val: 0.264 Test: 0.294\n",
            "105 33334.99 Train: 0.270 Val: 0.277 Test: 0.304 -- Best Val: 0.277 Test: 0.304\n",
            "106 33287.918 Train: 0.278 Val: 0.288 Test: 0.313 -- Best Val: 0.288 Test: 0.313\n",
            "107 33164.07 Train: 0.284 Val: 0.291 Test: 0.321 -- Best Val: 0.291 Test: 0.321\n",
            "108 33116.465 Train: 0.290 Val: 0.300 Test: 0.328 -- Best Val: 0.300 Test: 0.328\n",
            "109 33036.125 Train: 0.293 Val: 0.303 Test: 0.333 -- Best Val: 0.303 Test: 0.333\n",
            "110 32879.59 Train: 0.296 Val: 0.306 Test: 0.334 -- Best Val: 0.306 Test: 0.334\n",
            "111 32751.348 Train: 0.300 Val: 0.308 Test: 0.337 -- Best Val: 0.308 Test: 0.337\n",
            "112 32590.78 Train: 0.303 Val: 0.308 Test: 0.337 -- Best Val: 0.308 Test: 0.337\n",
            "113 32509.057 Train: 0.304 Val: 0.309 Test: 0.339 -- Best Val: 0.309 Test: 0.339\n",
            "114 32357.797 Train: 0.304 Val: 0.309 Test: 0.339 -- Best Val: 0.309 Test: 0.339\n",
            "115 32187.701 Train: 0.303 Val: 0.308 Test: 0.338 -- Best Val: 0.309 Test: 0.339\n",
            "116 32004.006 Train: 0.302 Val: 0.308 Test: 0.337 -- Best Val: 0.309 Test: 0.339\n",
            "117 31850.031 Train: 0.302 Val: 0.309 Test: 0.336 -- Best Val: 0.309 Test: 0.339\n",
            "118 31702.371 Train: 0.301 Val: 0.307 Test: 0.335 -- Best Val: 0.309 Test: 0.339\n",
            "119 31474.104 Train: 0.300 Val: 0.306 Test: 0.334 -- Best Val: 0.309 Test: 0.339\n",
            "120 31315.848 Train: 0.300 Val: 0.306 Test: 0.334 -- Best Val: 0.309 Test: 0.339\n",
            "121 31086.508 Train: 0.300 Val: 0.305 Test: 0.333 -- Best Val: 0.309 Test: 0.339\n",
            "122 30903.977 Train: 0.300 Val: 0.305 Test: 0.332 -- Best Val: 0.309 Test: 0.339\n",
            "123 30762.951 Train: 0.300 Val: 0.304 Test: 0.332 -- Best Val: 0.309 Test: 0.339\n",
            "124 30658.742 Train: 0.299 Val: 0.303 Test: 0.332 -- Best Val: 0.309 Test: 0.339\n",
            "125 30394.598 Train: 0.301 Val: 0.304 Test: 0.333 -- Best Val: 0.309 Test: 0.339\n",
            "126 30225.71 Train: 0.307 Val: 0.309 Test: 0.340 -- Best Val: 0.309 Test: 0.339\n",
            "127 30159.914 Train: 0.308 Val: 0.311 Test: 0.340 -- Best Val: 0.311 Test: 0.340\n",
            "128 29915.8 Train: 0.311 Val: 0.315 Test: 0.344 -- Best Val: 0.315 Test: 0.344\n",
            "129 29844.396 Train: 0.315 Val: 0.317 Test: 0.348 -- Best Val: 0.317 Test: 0.348\n",
            "130 29789.064 Train: 0.317 Val: 0.320 Test: 0.350 -- Best Val: 0.320 Test: 0.350\n",
            "131 29608.725 Train: 0.319 Val: 0.324 Test: 0.352 -- Best Val: 0.324 Test: 0.352\n",
            "132 29498.412 Train: 0.318 Val: 0.323 Test: 0.353 -- Best Val: 0.324 Test: 0.352\n",
            "133 29253.365 Train: 0.325 Val: 0.328 Test: 0.359 -- Best Val: 0.328 Test: 0.359\n",
            "134 29205.768 Train: 0.328 Val: 0.331 Test: 0.362 -- Best Val: 0.331 Test: 0.362\n",
            "135 29084.371 Train: 0.330 Val: 0.332 Test: 0.364 -- Best Val: 0.332 Test: 0.364\n",
            "136 29023.893 Train: 0.334 Val: 0.337 Test: 0.370 -- Best Val: 0.337 Test: 0.370\n",
            "137 28902.484 Train: 0.337 Val: 0.340 Test: 0.374 -- Best Val: 0.340 Test: 0.374\n",
            "138 28806.703 Train: 0.340 Val: 0.342 Test: 0.377 -- Best Val: 0.342 Test: 0.377\n",
            "139 28710.36 Train: 0.345 Val: 0.345 Test: 0.381 -- Best Val: 0.345 Test: 0.381\n",
            "140 28618.723 Train: 0.347 Val: 0.348 Test: 0.385 -- Best Val: 0.348 Test: 0.385\n",
            "141 28535.566 Train: 0.352 Val: 0.353 Test: 0.390 -- Best Val: 0.353 Test: 0.390\n",
            "142 28512.158 Train: 0.354 Val: 0.355 Test: 0.392 -- Best Val: 0.355 Test: 0.392\n",
            "143 28369.465 Train: 0.358 Val: 0.358 Test: 0.396 -- Best Val: 0.358 Test: 0.396\n",
            "144 28243.795 Train: 0.361 Val: 0.362 Test: 0.397 -- Best Val: 0.362 Test: 0.397\n",
            "145 28146.46 Train: 0.364 Val: 0.364 Test: 0.400 -- Best Val: 0.364 Test: 0.400\n",
            "146 28105.516 Train: 0.367 Val: 0.367 Test: 0.402 -- Best Val: 0.367 Test: 0.402\n",
            "147 28050.549 Train: 0.369 Val: 0.370 Test: 0.405 -- Best Val: 0.370 Test: 0.405\n",
            "148 28012.486 Train: 0.370 Val: 0.371 Test: 0.406 -- Best Val: 0.371 Test: 0.406\n",
            "149 27931.87 Train: 0.372 Val: 0.373 Test: 0.408 -- Best Val: 0.373 Test: 0.408\n",
            "150 27904.43 Train: 0.376 Val: 0.377 Test: 0.411 -- Best Val: 0.377 Test: 0.411\n",
            "151 27764.89 Train: 0.375 Val: 0.377 Test: 0.411 -- Best Val: 0.377 Test: 0.411\n",
            "152 27696.414 Train: 0.379 Val: 0.380 Test: 0.418 -- Best Val: 0.380 Test: 0.418\n",
            "153 27591.045 Train: 0.383 Val: 0.382 Test: 0.419 -- Best Val: 0.382 Test: 0.419\n",
            "154 27623.822 Train: 0.386 Val: 0.386 Test: 0.421 -- Best Val: 0.386 Test: 0.421\n",
            "155 27503.146 Train: 0.388 Val: 0.386 Test: 0.423 -- Best Val: 0.386 Test: 0.423\n",
            "156 27415.719 Train: 0.391 Val: 0.391 Test: 0.428 -- Best Val: 0.391 Test: 0.428\n",
            "157 27407.176 Train: 0.395 Val: 0.392 Test: 0.430 -- Best Val: 0.392 Test: 0.430\n",
            "158 27360.115 Train: 0.397 Val: 0.398 Test: 0.433 -- Best Val: 0.398 Test: 0.433\n",
            "159 27219.953 Train: 0.401 Val: 0.401 Test: 0.435 -- Best Val: 0.401 Test: 0.435\n",
            "160 27226.367 Train: 0.404 Val: 0.403 Test: 0.439 -- Best Val: 0.403 Test: 0.439\n",
            "161 27195.191 Train: 0.407 Val: 0.404 Test: 0.443 -- Best Val: 0.404 Test: 0.443\n",
            "162 27088.178 Train: 0.408 Val: 0.406 Test: 0.447 -- Best Val: 0.406 Test: 0.447\n",
            "163 27012.979 Train: 0.409 Val: 0.408 Test: 0.448 -- Best Val: 0.408 Test: 0.448\n",
            "164 26967.047 Train: 0.409 Val: 0.410 Test: 0.449 -- Best Val: 0.410 Test: 0.449\n",
            "165 26930.938 Train: 0.412 Val: 0.411 Test: 0.451 -- Best Val: 0.411 Test: 0.451\n",
            "166 26921.19 Train: 0.414 Val: 0.411 Test: 0.454 -- Best Val: 0.411 Test: 0.454\n",
            "167 26825.102 Train: 0.413 Val: 0.411 Test: 0.453 -- Best Val: 0.411 Test: 0.453\n",
            "168 26726.176 Train: 0.414 Val: 0.414 Test: 0.454 -- Best Val: 0.414 Test: 0.454\n",
            "169 26743.408 Train: 0.417 Val: 0.418 Test: 0.458 -- Best Val: 0.418 Test: 0.458\n",
            "170 26664.49 Train: 0.420 Val: 0.421 Test: 0.462 -- Best Val: 0.421 Test: 0.462\n",
            "171 26529.834 Train: 0.423 Val: 0.425 Test: 0.467 -- Best Val: 0.425 Test: 0.467\n",
            "172 26456.477 Train: 0.427 Val: 0.425 Test: 0.470 -- Best Val: 0.425 Test: 0.467\n",
            "173 26448.293 Train: 0.429 Val: 0.430 Test: 0.471 -- Best Val: 0.430 Test: 0.471\n",
            "174 26363.502 Train: 0.432 Val: 0.429 Test: 0.474 -- Best Val: 0.430 Test: 0.471\n",
            "175 26412.803 Train: 0.431 Val: 0.431 Test: 0.476 -- Best Val: 0.431 Test: 0.476\n",
            "176 26287.527 Train: 0.434 Val: 0.432 Test: 0.474 -- Best Val: 0.432 Test: 0.474\n",
            "177 26251.582 Train: 0.434 Val: 0.434 Test: 0.475 -- Best Val: 0.434 Test: 0.475\n",
            "178 26246.62 Train: 0.433 Val: 0.434 Test: 0.477 -- Best Val: 0.434 Test: 0.477\n",
            "179 26112.66 Train: 0.433 Val: 0.435 Test: 0.478 -- Best Val: 0.435 Test: 0.478\n",
            "180 26188.275 Train: 0.434 Val: 0.437 Test: 0.475 -- Best Val: 0.437 Test: 0.475\n",
            "181 26035.154 Train: 0.434 Val: 0.437 Test: 0.472 -- Best Val: 0.437 Test: 0.472\n",
            "182 25963.428 Train: 0.437 Val: 0.438 Test: 0.473 -- Best Val: 0.438 Test: 0.473\n",
            "183 25941.586 Train: 0.438 Val: 0.438 Test: 0.474 -- Best Val: 0.438 Test: 0.474\n",
            "184 25980.91 Train: 0.439 Val: 0.440 Test: 0.474 -- Best Val: 0.440 Test: 0.474\n",
            "185 25905.234 Train: 0.438 Val: 0.439 Test: 0.475 -- Best Val: 0.440 Test: 0.474\n",
            "186 25871.217 Train: 0.438 Val: 0.440 Test: 0.474 -- Best Val: 0.440 Test: 0.474\n",
            "187 25814.148 Train: 0.436 Val: 0.440 Test: 0.474 -- Best Val: 0.440 Test: 0.474\n",
            "188 25796.809 Train: 0.436 Val: 0.437 Test: 0.472 -- Best Val: 0.440 Test: 0.474\n",
            "189 25766.547 Train: 0.435 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "190 25659.006 Train: 0.434 Val: 0.437 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "191 25661.172 Train: 0.432 Val: 0.436 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "192 25585.225 Train: 0.431 Val: 0.436 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "193 25515.58 Train: 0.432 Val: 0.437 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "194 25473.246 Train: 0.432 Val: 0.438 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "195 25501.434 Train: 0.430 Val: 0.436 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "196 25380.848 Train: 0.431 Val: 0.436 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "197 25406.83 Train: 0.430 Val: 0.434 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "198 25346.307 Train: 0.430 Val: 0.432 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "199 25319.8 Train: 0.429 Val: 0.433 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "200 25293.098 Train: 0.427 Val: 0.432 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "201 25270.08 Train: 0.427 Val: 0.433 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "202 25182.574 Train: 0.426 Val: 0.431 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "203 25199.717 Train: 0.425 Val: 0.432 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "204 25135.303 Train: 0.425 Val: 0.432 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "205 25149.662 Train: 0.425 Val: 0.432 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "206 25054.578 Train: 0.426 Val: 0.433 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "207 25055.793 Train: 0.426 Val: 0.433 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "208 25027.016 Train: 0.426 Val: 0.432 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "209 24966.197 Train: 0.426 Val: 0.433 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "210 24961.428 Train: 0.426 Val: 0.434 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "211 24921.773 Train: 0.427 Val: 0.435 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "212 24868.979 Train: 0.427 Val: 0.434 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "213 24850.434 Train: 0.426 Val: 0.432 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "214 24813.076 Train: 0.427 Val: 0.433 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "215 24760.768 Train: 0.426 Val: 0.432 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "216 24733.344 Train: 0.426 Val: 0.432 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "217 24686.541 Train: 0.426 Val: 0.432 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "218 24676.207 Train: 0.426 Val: 0.431 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "219 24646.34 Train: 0.428 Val: 0.432 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "220 24621.924 Train: 0.427 Val: 0.431 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "221 24628.432 Train: 0.427 Val: 0.430 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "222 24595.305 Train: 0.427 Val: 0.431 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "223 24565.248 Train: 0.428 Val: 0.432 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "224 24463.312 Train: 0.428 Val: 0.432 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "225 24521.22 Train: 0.428 Val: 0.432 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "226 24501.875 Train: 0.428 Val: 0.432 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "227 24428.137 Train: 0.428 Val: 0.433 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "228 24435.05 Train: 0.428 Val: 0.432 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "229 24389.623 Train: 0.426 Val: 0.432 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "230 24369.523 Train: 0.427 Val: 0.433 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "231 24344.543 Train: 0.427 Val: 0.434 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "232 24339.617 Train: 0.427 Val: 0.433 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "233 24341.36 Train: 0.428 Val: 0.433 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "234 24317.344 Train: 0.428 Val: 0.435 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "235 24260.04 Train: 0.428 Val: 0.434 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "236 24250.441 Train: 0.427 Val: 0.433 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "237 24235.146 Train: 0.428 Val: 0.434 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "238 24259.533 Train: 0.428 Val: 0.434 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "239 24217.664 Train: 0.427 Val: 0.433 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "240 24179.06 Train: 0.428 Val: 0.434 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "241 24164.576 Train: 0.428 Val: 0.434 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "242 24084.305 Train: 0.428 Val: 0.434 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "243 24066.727 Train: 0.428 Val: 0.433 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "244 24105.158 Train: 0.427 Val: 0.433 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "245 24121.463 Train: 0.428 Val: 0.433 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "246 24120.363 Train: 0.427 Val: 0.433 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "247 24072.506 Train: 0.426 Val: 0.434 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "248 24005.82 Train: 0.428 Val: 0.434 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "249 24055.21 Train: 0.428 Val: 0.434 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "250 23960.63 Train: 0.427 Val: 0.434 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "251 23969.945 Train: 0.427 Val: 0.433 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "252 23907.596 Train: 0.426 Val: 0.433 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "253 23935.799 Train: 0.426 Val: 0.433 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "254 23962.535 Train: 0.425 Val: 0.433 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "255 23919.777 Train: 0.424 Val: 0.432 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "256 23856.016 Train: 0.426 Val: 0.432 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "257 23893.53 Train: 0.426 Val: 0.434 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "258 23812.928 Train: 0.424 Val: 0.432 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "259 23809.771 Train: 0.423 Val: 0.430 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "260 23771.893 Train: 0.424 Val: 0.430 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "261 23758.02 Train: 0.424 Val: 0.430 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "262 23704.193 Train: 0.424 Val: 0.430 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "263 23765.895 Train: 0.423 Val: 0.428 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "264 23698.5 Train: 0.423 Val: 0.429 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "265 23723.445 Train: 0.423 Val: 0.428 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "266 23725.215 Train: 0.423 Val: 0.428 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "267 23697.59 Train: 0.422 Val: 0.427 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "268 23678.963 Train: 0.422 Val: 0.427 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "269 23656.443 Train: 0.422 Val: 0.427 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "270 23587.885 Train: 0.423 Val: 0.427 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "271 23576.023 Train: 0.423 Val: 0.428 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "272 23655.412 Train: 0.423 Val: 0.427 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "273 23587.49 Train: 0.423 Val: 0.426 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "274 23546.322 Train: 0.423 Val: 0.426 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "275 23582.69 Train: 0.422 Val: 0.426 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "276 23511.459 Train: 0.421 Val: 0.426 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "277 23525.787 Train: 0.422 Val: 0.426 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "278 23484.162 Train: 0.423 Val: 0.424 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "279 23484.74 Train: 0.423 Val: 0.425 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "280 23421.8 Train: 0.423 Val: 0.426 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "281 23400.035 Train: 0.422 Val: 0.425 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "282 23455.805 Train: 0.423 Val: 0.425 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "283 23365.996 Train: 0.422 Val: 0.425 Test: 0.450 -- Best Val: 0.440 Test: 0.474\n",
            "284 23452.15 Train: 0.422 Val: 0.424 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "285 23402.193 Train: 0.420 Val: 0.424 Test: 0.450 -- Best Val: 0.440 Test: 0.474\n",
            "286 23342.088 Train: 0.421 Val: 0.424 Test: 0.450 -- Best Val: 0.440 Test: 0.474\n",
            "287 23303.326 Train: 0.422 Val: 0.424 Test: 0.450 -- Best Val: 0.440 Test: 0.474\n",
            "288 23310.633 Train: 0.422 Val: 0.426 Test: 0.450 -- Best Val: 0.440 Test: 0.474\n",
            "289 23289.97 Train: 0.422 Val: 0.425 Test: 0.450 -- Best Val: 0.440 Test: 0.474\n",
            "290 23261.385 Train: 0.422 Val: 0.425 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "291 23300.266 Train: 0.421 Val: 0.425 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "292 23269.654 Train: 0.421 Val: 0.425 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "293 23226.31 Train: 0.421 Val: 0.424 Test: 0.450 -- Best Val: 0.440 Test: 0.474\n",
            "294 23271.744 Train: 0.421 Val: 0.425 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "295 23204.697 Train: 0.422 Val: 0.425 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "296 23135.297 Train: 0.422 Val: 0.425 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "297 23177.914 Train: 0.421 Val: 0.425 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "298 23235.297 Train: 0.421 Val: 0.424 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "299 23139.857 Train: 0.422 Val: 0.424 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "300 23146.324 Train: 0.421 Val: 0.424 Test: 0.451 -- Best Val: 0.440 Test: 0.474\n",
            "301 23104.65 Train: 0.422 Val: 0.425 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "302 23100.771 Train: 0.422 Val: 0.424 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "303 23054.178 Train: 0.421 Val: 0.424 Test: 0.452 -- Best Val: 0.440 Test: 0.474\n",
            "304 23101.018 Train: 0.422 Val: 0.425 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "305 23050.541 Train: 0.422 Val: 0.425 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "306 23038.969 Train: 0.422 Val: 0.425 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "307 23030.547 Train: 0.423 Val: 0.425 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "308 23007.686 Train: 0.423 Val: 0.425 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "309 23052.87 Train: 0.422 Val: 0.426 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "310 22981.834 Train: 0.423 Val: 0.426 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "311 22914.135 Train: 0.423 Val: 0.425 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "312 22942.818 Train: 0.423 Val: 0.425 Test: 0.453 -- Best Val: 0.440 Test: 0.474\n",
            "313 22953.72 Train: 0.423 Val: 0.426 Test: 0.454 -- Best Val: 0.440 Test: 0.474\n",
            "314 22974.844 Train: 0.423 Val: 0.427 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "315 22950.465 Train: 0.423 Val: 0.425 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "316 22895.324 Train: 0.423 Val: 0.427 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "317 22931.84 Train: 0.423 Val: 0.426 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "318 22892.85 Train: 0.423 Val: 0.427 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "319 22878.459 Train: 0.423 Val: 0.426 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "320 22841.182 Train: 0.423 Val: 0.427 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "321 22814.09 Train: 0.423 Val: 0.426 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "322 22797.754 Train: 0.424 Val: 0.428 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "323 22785.42 Train: 0.424 Val: 0.428 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "324 22776.27 Train: 0.424 Val: 0.428 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "325 22780.127 Train: 0.424 Val: 0.427 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "326 22749.39 Train: 0.424 Val: 0.427 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "327 22688.275 Train: 0.425 Val: 0.428 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "328 22700.102 Train: 0.425 Val: 0.428 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "329 22714.533 Train: 0.424 Val: 0.428 Test: 0.455 -- Best Val: 0.440 Test: 0.474\n",
            "330 22719.055 Train: 0.425 Val: 0.429 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "331 22678.54 Train: 0.424 Val: 0.429 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "332 22619.875 Train: 0.425 Val: 0.429 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "333 22654.031 Train: 0.424 Val: 0.429 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "334 22615.652 Train: 0.425 Val: 0.429 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "335 22637.117 Train: 0.425 Val: 0.429 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "336 22591.207 Train: 0.424 Val: 0.429 Test: 0.456 -- Best Val: 0.440 Test: 0.474\n",
            "337 22593.193 Train: 0.425 Val: 0.430 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "338 22626.783 Train: 0.425 Val: 0.429 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "339 22556.672 Train: 0.425 Val: 0.429 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "340 22534.203 Train: 0.426 Val: 0.430 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "341 22556.137 Train: 0.426 Val: 0.430 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "342 22603.574 Train: 0.425 Val: 0.430 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "343 22558.082 Train: 0.426 Val: 0.430 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "344 22487.877 Train: 0.425 Val: 0.430 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "345 22438.988 Train: 0.425 Val: 0.430 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "346 22475.877 Train: 0.425 Val: 0.431 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "347 22486.889 Train: 0.426 Val: 0.431 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "348 22423.543 Train: 0.425 Val: 0.431 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "349 22434.816 Train: 0.427 Val: 0.432 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "350 22434.09 Train: 0.427 Val: 0.430 Test: 0.457 -- Best Val: 0.440 Test: 0.474\n",
            "351 22391.846 Train: 0.426 Val: 0.432 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "352 22411.445 Train: 0.426 Val: 0.431 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "353 22403.316 Train: 0.426 Val: 0.431 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "354 22397.945 Train: 0.426 Val: 0.431 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "355 22369.332 Train: 0.426 Val: 0.431 Test: 0.458 -- Best Val: 0.440 Test: 0.474\n",
            "356 22350.617 Train: 0.427 Val: 0.432 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "357 22351.13 Train: 0.427 Val: 0.431 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "358 22349.965 Train: 0.428 Val: 0.433 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "359 22286.709 Train: 0.427 Val: 0.433 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "360 22286.854 Train: 0.427 Val: 0.434 Test: 0.459 -- Best Val: 0.440 Test: 0.474\n",
            "361 22284.197 Train: 0.427 Val: 0.433 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "362 22294.916 Train: 0.427 Val: 0.433 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "363 22261.438 Train: 0.427 Val: 0.434 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "364 22241.51 Train: 0.428 Val: 0.432 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "365 22237.953 Train: 0.428 Val: 0.434 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "366 22187.895 Train: 0.429 Val: 0.432 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "367 22285.479 Train: 0.428 Val: 0.433 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "368 22193.113 Train: 0.428 Val: 0.431 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "369 22141.9 Train: 0.428 Val: 0.432 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "370 22243.184 Train: 0.428 Val: 0.433 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "371 22168.203 Train: 0.429 Val: 0.433 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "372 22169.443 Train: 0.428 Val: 0.432 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "373 22142.947 Train: 0.428 Val: 0.431 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "374 22135.197 Train: 0.429 Val: 0.432 Test: 0.460 -- Best Val: 0.440 Test: 0.474\n",
            "375 22112.656 Train: 0.429 Val: 0.433 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "376 22067.969 Train: 0.429 Val: 0.432 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "377 22122.383 Train: 0.430 Val: 0.433 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "378 22057.252 Train: 0.429 Val: 0.432 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "379 22057.545 Train: 0.429 Val: 0.433 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "380 22069.416 Train: 0.430 Val: 0.434 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "381 22055.355 Train: 0.429 Val: 0.432 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "382 21983.855 Train: 0.430 Val: 0.433 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "383 22025.238 Train: 0.430 Val: 0.433 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "384 22061.58 Train: 0.430 Val: 0.433 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "385 21976.45 Train: 0.430 Val: 0.433 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "386 21999.53 Train: 0.429 Val: 0.433 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "387 21999.1 Train: 0.430 Val: 0.434 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "388 21982.732 Train: 0.430 Val: 0.434 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "389 21951.75 Train: 0.430 Val: 0.434 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "390 21929.277 Train: 0.431 Val: 0.434 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "391 21953.943 Train: 0.430 Val: 0.434 Test: 0.461 -- Best Val: 0.440 Test: 0.474\n",
            "392 21944.94 Train: 0.430 Val: 0.433 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "393 21927.09 Train: 0.430 Val: 0.434 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "394 21891.092 Train: 0.431 Val: 0.433 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "395 21912.736 Train: 0.430 Val: 0.433 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "396 21895.951 Train: 0.429 Val: 0.433 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "397 21834.146 Train: 0.430 Val: 0.433 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "398 21847.309 Train: 0.430 Val: 0.434 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "399 21839.7 Train: 0.431 Val: 0.434 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "400 21823.613 Train: 0.432 Val: 0.434 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "401 21799.0 Train: 0.431 Val: 0.434 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "402 21825.38 Train: 0.431 Val: 0.434 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "403 21796.258 Train: 0.431 Val: 0.434 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "404 21798.828 Train: 0.432 Val: 0.433 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "405 21809.785 Train: 0.431 Val: 0.433 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "406 21769.748 Train: 0.431 Val: 0.433 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "407 21759.95 Train: 0.431 Val: 0.434 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "408 21768.547 Train: 0.432 Val: 0.434 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "409 21713.338 Train: 0.432 Val: 0.433 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "410 21692.86 Train: 0.432 Val: 0.434 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "411 21729.807 Train: 0.432 Val: 0.434 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "412 21743.773 Train: 0.431 Val: 0.433 Test: 0.462 -- Best Val: 0.440 Test: 0.474\n",
            "413 21663.578 Train: 0.433 Val: 0.435 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "414 21702.37 Train: 0.432 Val: 0.435 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "415 21686.05 Train: 0.432 Val: 0.433 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "416 21679.453 Train: 0.433 Val: 0.434 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "417 21691.258 Train: 0.432 Val: 0.432 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "418 21627.852 Train: 0.432 Val: 0.433 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "419 21582.785 Train: 0.432 Val: 0.434 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "420 21606.756 Train: 0.433 Val: 0.435 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "421 21618.164 Train: 0.433 Val: 0.435 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "422 21590.246 Train: 0.432 Val: 0.434 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "423 21589.045 Train: 0.433 Val: 0.434 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "424 21597.46 Train: 0.433 Val: 0.435 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "425 21595.266 Train: 0.432 Val: 0.435 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "426 21615.523 Train: 0.432 Val: 0.435 Test: 0.463 -- Best Val: 0.440 Test: 0.474\n",
            "427 21574.055 Train: 0.433 Val: 0.435 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "428 21557.646 Train: 0.433 Val: 0.435 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "429 21567.754 Train: 0.433 Val: 0.435 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "430 21514.092 Train: 0.433 Val: 0.434 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "431 21540.244 Train: 0.433 Val: 0.435 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "432 21540.637 Train: 0.433 Val: 0.435 Test: 0.464 -- Best Val: 0.440 Test: 0.474\n",
            "433 21519.316 Train: 0.433 Val: 0.436 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "434 21462.682 Train: 0.434 Val: 0.437 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "435 21484.023 Train: 0.433 Val: 0.435 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "436 21490.562 Train: 0.433 Val: 0.436 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "437 21452.48 Train: 0.434 Val: 0.436 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "438 21472.836 Train: 0.433 Val: 0.435 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "439 21475.426 Train: 0.434 Val: 0.435 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "440 21419.746 Train: 0.434 Val: 0.437 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "441 21445.234 Train: 0.431 Val: 0.436 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "442 21406.553 Train: 0.434 Val: 0.437 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "443 21416.25 Train: 0.434 Val: 0.436 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "444 21428.426 Train: 0.434 Val: 0.436 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "445 21415.84 Train: 0.433 Val: 0.436 Test: 0.465 -- Best Val: 0.440 Test: 0.474\n",
            "446 21389.828 Train: 0.435 Val: 0.437 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "447 21402.14 Train: 0.434 Val: 0.436 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "448 21380.502 Train: 0.434 Val: 0.436 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "449 21385.44 Train: 0.433 Val: 0.436 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "450 21300.959 Train: 0.434 Val: 0.436 Test: 0.466 -- Best Val: 0.440 Test: 0.474\n",
            "451 21360.084 Train: 0.435 Val: 0.437 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "452 21356.002 Train: 0.435 Val: 0.436 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "453 21318.14 Train: 0.434 Val: 0.437 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "454 21340.41 Train: 0.435 Val: 0.437 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "455 21270.291 Train: 0.435 Val: 0.437 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "456 21312.973 Train: 0.434 Val: 0.435 Test: 0.468 -- Best Val: 0.440 Test: 0.474\n",
            "457 21255.002 Train: 0.435 Val: 0.436 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "458 21270.906 Train: 0.435 Val: 0.436 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "459 21280.377 Train: 0.435 Val: 0.437 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "460 21237.742 Train: 0.435 Val: 0.437 Test: 0.468 -- Best Val: 0.440 Test: 0.474\n",
            "461 21262.15 Train: 0.434 Val: 0.437 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "462 21226.617 Train: 0.436 Val: 0.436 Test: 0.468 -- Best Val: 0.440 Test: 0.474\n",
            "463 21252.98 Train: 0.434 Val: 0.436 Test: 0.468 -- Best Val: 0.440 Test: 0.474\n",
            "464 21263.984 Train: 0.434 Val: 0.437 Test: 0.467 -- Best Val: 0.440 Test: 0.474\n",
            "465 21238.836 Train: 0.435 Val: 0.436 Test: 0.468 -- Best Val: 0.440 Test: 0.474\n",
            "466 21215.705 Train: 0.435 Val: 0.436 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "467 21219.027 Train: 0.436 Val: 0.437 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "468 21205.656 Train: 0.434 Val: 0.437 Test: 0.468 -- Best Val: 0.440 Test: 0.474\n",
            "469 21205.652 Train: 0.435 Val: 0.436 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "470 21189.977 Train: 0.436 Val: 0.436 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "471 21234.453 Train: 0.436 Val: 0.437 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "472 21171.64 Train: 0.435 Val: 0.437 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "473 21141.896 Train: 0.436 Val: 0.437 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "474 21139.488 Train: 0.435 Val: 0.437 Test: 0.468 -- Best Val: 0.440 Test: 0.474\n",
            "475 21179.934 Train: 0.435 Val: 0.437 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "476 21135.666 Train: 0.437 Val: 0.438 Test: 0.468 -- Best Val: 0.440 Test: 0.474\n",
            "477 21169.299 Train: 0.437 Val: 0.437 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "478 21109.613 Train: 0.437 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "479 21148.4 Train: 0.436 Val: 0.438 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "480 21102.928 Train: 0.436 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "481 21105.174 Train: 0.438 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "482 21104.275 Train: 0.438 Val: 0.438 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "483 21103.5 Train: 0.437 Val: 0.438 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "484 21124.377 Train: 0.438 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "485 21126.227 Train: 0.437 Val: 0.438 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "486 21076.209 Train: 0.436 Val: 0.438 Test: 0.468 -- Best Val: 0.440 Test: 0.474\n",
            "487 21043.895 Train: 0.437 Val: 0.439 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "488 21087.629 Train: 0.437 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "489 21075.63 Train: 0.437 Val: 0.438 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "490 21050.225 Train: 0.438 Val: 0.437 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "491 21011.994 Train: 0.438 Val: 0.438 Test: 0.471 -- Best Val: 0.440 Test: 0.474\n",
            "492 21043.965 Train: 0.438 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "493 21040.027 Train: 0.438 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "494 20980.025 Train: 0.439 Val: 0.439 Test: 0.471 -- Best Val: 0.440 Test: 0.474\n",
            "495 20997.658 Train: 0.438 Val: 0.439 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "496 20984.768 Train: 0.438 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "497 21003.963 Train: 0.437 Val: 0.438 Test: 0.469 -- Best Val: 0.440 Test: 0.474\n",
            "498 20934.986 Train: 0.438 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "499 20992.752 Train: 0.438 Val: 0.439 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "500 20973.732 Train: 0.437 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "501 20977.137 Train: 0.437 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "502 20909.76 Train: 0.437 Val: 0.439 Test: 0.471 -- Best Val: 0.440 Test: 0.474\n",
            "503 20940.684 Train: 0.438 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "504 20953.697 Train: 0.437 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "505 20903.754 Train: 0.438 Val: 0.438 Test: 0.472 -- Best Val: 0.440 Test: 0.474\n",
            "506 20936.787 Train: 0.438 Val: 0.438 Test: 0.471 -- Best Val: 0.440 Test: 0.474\n",
            "507 20944.318 Train: 0.439 Val: 0.438 Test: 0.470 -- Best Val: 0.440 Test: 0.474\n",
            "508 20924.04 Train: 0.438 Val: 0.439 Test: 0.471 -- Best Val: 0.440 Test: 0.474\n",
            "509 20889.914 Train: 0.438 Val: 0.438 Test: 0.471 -- Best Val: 0.440 Test: 0.474\n",
            "510 20908.303 Train: 0.439 Val: 0.438 Test: 0.472 -- Best Val: 0.440 Test: 0.474\n",
            "511 20900.236 Train: 0.439 Val: 0.439 Test: 0.472 -- Best Val: 0.440 Test: 0.474\n",
            "512 20934.898 Train: 0.439 Val: 0.439 Test: 0.472 -- Best Val: 0.440 Test: 0.474\n",
            "513 20899.305 Train: 0.439 Val: 0.440 Test: 0.472 -- Best Val: 0.440 Test: 0.472\n",
            "514 20901.555 Train: 0.439 Val: 0.440 Test: 0.472 -- Best Val: 0.440 Test: 0.472\n",
            "515 20828.305 Train: 0.438 Val: 0.438 Test: 0.471 -- Best Val: 0.440 Test: 0.472\n",
            "516 20864.715 Train: 0.439 Val: 0.439 Test: 0.472 -- Best Val: 0.440 Test: 0.472\n",
            "517 20838.385 Train: 0.439 Val: 0.438 Test: 0.471 -- Best Val: 0.440 Test: 0.472\n",
            "518 20870.05 Train: 0.439 Val: 0.439 Test: 0.472 -- Best Val: 0.440 Test: 0.472\n",
            "519 20828.227 Train: 0.439 Val: 0.439 Test: 0.472 -- Best Val: 0.440 Test: 0.472\n",
            "520 20850.314 Train: 0.439 Val: 0.441 Test: 0.473 -- Best Val: 0.441 Test: 0.473\n",
            "521 20829.793 Train: 0.439 Val: 0.440 Test: 0.473 -- Best Val: 0.441 Test: 0.473\n",
            "522 20851.322 Train: 0.440 Val: 0.440 Test: 0.473 -- Best Val: 0.441 Test: 0.473\n",
            "523 20827.9 Train: 0.439 Val: 0.440 Test: 0.473 -- Best Val: 0.441 Test: 0.473\n",
            "524 20805.002 Train: 0.439 Val: 0.440 Test: 0.473 -- Best Val: 0.441 Test: 0.473\n",
            "525 20831.492 Train: 0.439 Val: 0.441 Test: 0.473 -- Best Val: 0.441 Test: 0.473\n",
            "526 20803.256 Train: 0.439 Val: 0.440 Test: 0.473 -- Best Val: 0.441 Test: 0.473\n",
            "527 20795.463 Train: 0.439 Val: 0.440 Test: 0.472 -- Best Val: 0.441 Test: 0.473\n",
            "528 20799.883 Train: 0.439 Val: 0.440 Test: 0.473 -- Best Val: 0.441 Test: 0.473\n",
            "529 20764.105 Train: 0.438 Val: 0.441 Test: 0.473 -- Best Val: 0.441 Test: 0.473\n",
            "530 20777.887 Train: 0.439 Val: 0.440 Test: 0.473 -- Best Val: 0.441 Test: 0.473\n",
            "531 20790.086 Train: 0.438 Val: 0.440 Test: 0.474 -- Best Val: 0.441 Test: 0.473\n",
            "532 20792.828 Train: 0.438 Val: 0.442 Test: 0.473 -- Best Val: 0.442 Test: 0.473\n",
            "533 20745.498 Train: 0.438 Val: 0.441 Test: 0.472 -- Best Val: 0.442 Test: 0.473\n",
            "534 20770.803 Train: 0.440 Val: 0.441 Test: 0.474 -- Best Val: 0.442 Test: 0.473\n",
            "535 20742.34 Train: 0.439 Val: 0.441 Test: 0.474 -- Best Val: 0.442 Test: 0.473\n",
            "536 20739.744 Train: 0.440 Val: 0.441 Test: 0.473 -- Best Val: 0.442 Test: 0.473\n",
            "537 20753.695 Train: 0.440 Val: 0.441 Test: 0.473 -- Best Val: 0.442 Test: 0.473\n",
            "538 20736.645 Train: 0.440 Val: 0.442 Test: 0.474 -- Best Val: 0.442 Test: 0.473\n",
            "539 20715.477 Train: 0.440 Val: 0.442 Test: 0.474 -- Best Val: 0.442 Test: 0.473\n",
            "540 20719.639 Train: 0.440 Val: 0.442 Test: 0.473 -- Best Val: 0.442 Test: 0.473\n",
            "541 20755.871 Train: 0.440 Val: 0.442 Test: 0.474 -- Best Val: 0.442 Test: 0.473\n",
            "542 20705.143 Train: 0.440 Val: 0.442 Test: 0.474 -- Best Val: 0.442 Test: 0.473\n",
            "543 20700.521 Train: 0.440 Val: 0.441 Test: 0.473 -- Best Val: 0.442 Test: 0.473\n",
            "544 20711.064 Train: 0.440 Val: 0.443 Test: 0.473 -- Best Val: 0.443 Test: 0.473\n",
            "545 20692.021 Train: 0.439 Val: 0.441 Test: 0.474 -- Best Val: 0.443 Test: 0.473\n",
            "546 20695.562 Train: 0.440 Val: 0.443 Test: 0.475 -- Best Val: 0.443 Test: 0.475\n",
            "547 20740.102 Train: 0.439 Val: 0.443 Test: 0.474 -- Best Val: 0.443 Test: 0.475\n",
            "548 20707.205 Train: 0.440 Val: 0.443 Test: 0.474 -- Best Val: 0.443 Test: 0.475\n",
            "549 20705.143 Train: 0.441 Val: 0.443 Test: 0.474 -- Best Val: 0.443 Test: 0.474\n",
            "550 20652.104 Train: 0.440 Val: 0.443 Test: 0.475 -- Best Val: 0.443 Test: 0.474\n",
            "551 20665.166 Train: 0.440 Val: 0.442 Test: 0.474 -- Best Val: 0.443 Test: 0.474\n",
            "552 20680.176 Train: 0.440 Val: 0.442 Test: 0.474 -- Best Val: 0.443 Test: 0.474\n",
            "553 20671.83 Train: 0.440 Val: 0.443 Test: 0.475 -- Best Val: 0.443 Test: 0.474\n",
            "554 20667.074 Train: 0.440 Val: 0.442 Test: 0.473 -- Best Val: 0.443 Test: 0.474\n",
            "555 20640.46 Train: 0.439 Val: 0.443 Test: 0.474 -- Best Val: 0.443 Test: 0.474\n",
            "556 20666.885 Train: 0.440 Val: 0.443 Test: 0.475 -- Best Val: 0.443 Test: 0.474\n",
            "557 20663.861 Train: 0.440 Val: 0.443 Test: 0.475 -- Best Val: 0.443 Test: 0.475\n",
            "558 20637.146 Train: 0.441 Val: 0.442 Test: 0.475 -- Best Val: 0.443 Test: 0.475\n",
            "559 20677.902 Train: 0.439 Val: 0.443 Test: 0.475 -- Best Val: 0.443 Test: 0.475\n",
            "560 20634.074 Train: 0.439 Val: 0.443 Test: 0.474 -- Best Val: 0.443 Test: 0.475\n",
            "561 20650.32 Train: 0.439 Val: 0.443 Test: 0.475 -- Best Val: 0.443 Test: 0.475\n",
            "562 20649.236 Train: 0.440 Val: 0.444 Test: 0.475 -- Best Val: 0.444 Test: 0.475\n",
            "563 20632.402 Train: 0.439 Val: 0.443 Test: 0.475 -- Best Val: 0.444 Test: 0.475\n",
            "564 20603.22 Train: 0.441 Val: 0.443 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "565 20600.037 Train: 0.441 Val: 0.444 Test: 0.475 -- Best Val: 0.444 Test: 0.475\n",
            "566 20606.764 Train: 0.439 Val: 0.443 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "567 20616.156 Train: 0.439 Val: 0.444 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "568 20605.045 Train: 0.438 Val: 0.443 Test: 0.475 -- Best Val: 0.444 Test: 0.475\n",
            "569 20593.08 Train: 0.438 Val: 0.442 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "570 20585.902 Train: 0.438 Val: 0.443 Test: 0.475 -- Best Val: 0.444 Test: 0.475\n",
            "571 20553.328 Train: 0.439 Val: 0.444 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "572 20584.195 Train: 0.438 Val: 0.443 Test: 0.475 -- Best Val: 0.444 Test: 0.475\n",
            "573 20577.629 Train: 0.439 Val: 0.443 Test: 0.475 -- Best Val: 0.444 Test: 0.475\n",
            "574 20566.66 Train: 0.438 Val: 0.443 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "575 20531.08 Train: 0.437 Val: 0.442 Test: 0.473 -- Best Val: 0.444 Test: 0.475\n",
            "576 20547.873 Train: 0.437 Val: 0.442 Test: 0.472 -- Best Val: 0.444 Test: 0.475\n",
            "577 20565.69 Train: 0.438 Val: 0.443 Test: 0.475 -- Best Val: 0.444 Test: 0.475\n",
            "578 20526.594 Train: 0.437 Val: 0.442 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "579 20541.592 Train: 0.438 Val: 0.443 Test: 0.475 -- Best Val: 0.444 Test: 0.475\n",
            "580 20541.068 Train: 0.437 Val: 0.443 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "581 20523.87 Train: 0.437 Val: 0.443 Test: 0.473 -- Best Val: 0.444 Test: 0.475\n",
            "582 20499.613 Train: 0.437 Val: 0.442 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "583 20545.328 Train: 0.437 Val: 0.442 Test: 0.472 -- Best Val: 0.444 Test: 0.475\n",
            "584 20496.523 Train: 0.437 Val: 0.442 Test: 0.473 -- Best Val: 0.444 Test: 0.475\n",
            "585 20545.38 Train: 0.438 Val: 0.443 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "586 20527.434 Train: 0.437 Val: 0.442 Test: 0.475 -- Best Val: 0.444 Test: 0.475\n",
            "587 20497.053 Train: 0.438 Val: 0.442 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "588 20486.795 Train: 0.437 Val: 0.442 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "589 20483.424 Train: 0.437 Val: 0.441 Test: 0.472 -- Best Val: 0.444 Test: 0.475\n",
            "590 20493.834 Train: 0.438 Val: 0.443 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "591 20491.521 Train: 0.437 Val: 0.442 Test: 0.474 -- Best Val: 0.444 Test: 0.475\n",
            "592 20471.338 Train: 0.437 Val: 0.442 Test: 0.471 -- Best Val: 0.444 Test: 0.475\n",
            "593 20489.889 Train: 0.437 Val: 0.442 Test: 0.473 -- Best Val: 0.444 Test: 0.475\n",
            "594 20489.51 Train: 0.436 Val: 0.441 Test: 0.473 -- Best Val: 0.444 Test: 0.475\n",
            "595 20462.229 Train: 0.436 Val: 0.441 Test: 0.473 -- Best Val: 0.444 Test: 0.475\n",
            "596 20465.367 Train: 0.437 Val: 0.441 Test: 0.472 -- Best Val: 0.444 Test: 0.475\n",
            "597 20487.572 Train: 0.437 Val: 0.442 Test: 0.472 -- Best Val: 0.444 Test: 0.475\n",
            "598 20444.383 Train: 0.437 Val: 0.441 Test: 0.471 -- Best Val: 0.444 Test: 0.475\n",
            "599 20436.064 Train: 0.436 Val: 0.441 Test: 0.472 -- Best Val: 0.444 Test: 0.475\n",
            "600 20434.809 Train: 0.436 Val: 0.441 Test: 0.472 -- Best Val: 0.444 Test: 0.475\n",
            "601 20428.068 Train: 0.436 Val: 0.441 Test: 0.473 -- Best Val: 0.444 Test: 0.475\n",
            "602 20432.133 Train: 0.435 Val: 0.439 Test: 0.470 -- Best Val: 0.444 Test: 0.475\n",
            "603 20447.047 Train: 0.436 Val: 0.441 Test: 0.471 -- Best Val: 0.444 Test: 0.475\n",
            "604 20438.87 Train: 0.435 Val: 0.440 Test: 0.470 -- Best Val: 0.444 Test: 0.475\n",
            "605 20426.367 Train: 0.435 Val: 0.440 Test: 0.470 -- Best Val: 0.444 Test: 0.475\n",
            "606 20445.266 Train: 0.435 Val: 0.440 Test: 0.470 -- Best Val: 0.444 Test: 0.475\n",
            "607 20420.492 Train: 0.435 Val: 0.440 Test: 0.470 -- Best Val: 0.444 Test: 0.475\n",
            "608 20425.633 Train: 0.433 Val: 0.438 Test: 0.467 -- Best Val: 0.444 Test: 0.475\n",
            "609 20415.219 Train: 0.434 Val: 0.438 Test: 0.469 -- Best Val: 0.444 Test: 0.475\n",
            "610 20418.355 Train: 0.434 Val: 0.438 Test: 0.468 -- Best Val: 0.444 Test: 0.475\n",
            "611 20426.074 Train: 0.435 Val: 0.439 Test: 0.469 -- Best Val: 0.444 Test: 0.475\n",
            "612 20401.215 Train: 0.434 Val: 0.439 Test: 0.468 -- Best Val: 0.444 Test: 0.475\n",
            "613 20400.807 Train: 0.434 Val: 0.438 Test: 0.467 -- Best Val: 0.444 Test: 0.475\n",
            "614 20411.125 Train: 0.434 Val: 0.438 Test: 0.469 -- Best Val: 0.444 Test: 0.475\n",
            "615 20369.684 Train: 0.434 Val: 0.438 Test: 0.468 -- Best Val: 0.444 Test: 0.475\n",
            "616 20376.95 Train: 0.434 Val: 0.440 Test: 0.469 -- Best Val: 0.444 Test: 0.475\n",
            "617 20379.178 Train: 0.433 Val: 0.437 Test: 0.467 -- Best Val: 0.444 Test: 0.475\n",
            "618 20360.375 Train: 0.433 Val: 0.437 Test: 0.466 -- Best Val: 0.444 Test: 0.475\n",
            "619 20345.906 Train: 0.433 Val: 0.438 Test: 0.467 -- Best Val: 0.444 Test: 0.475\n",
            "620 20357.969 Train: 0.432 Val: 0.437 Test: 0.465 -- Best Val: 0.444 Test: 0.475\n",
            "621 20362.334 Train: 0.433 Val: 0.438 Test: 0.466 -- Best Val: 0.444 Test: 0.475\n",
            "622 20328.738 Train: 0.433 Val: 0.438 Test: 0.466 -- Best Val: 0.444 Test: 0.475\n",
            "623 20371.469 Train: 0.433 Val: 0.437 Test: 0.466 -- Best Val: 0.444 Test: 0.475\n",
            "624 20349.668 Train: 0.432 Val: 0.438 Test: 0.465 -- Best Val: 0.444 Test: 0.475\n",
            "625 20374.781 Train: 0.432 Val: 0.438 Test: 0.465 -- Best Val: 0.444 Test: 0.475\n",
            "626 20366.545 Train: 0.433 Val: 0.438 Test: 0.466 -- Best Val: 0.444 Test: 0.475\n",
            "627 20334.969 Train: 0.433 Val: 0.437 Test: 0.469 -- Best Val: 0.444 Test: 0.475\n",
            "628 20333.604 Train: 0.432 Val: 0.437 Test: 0.465 -- Best Val: 0.444 Test: 0.475\n",
            "629 20341.248 Train: 0.431 Val: 0.437 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "630 20293.738 Train: 0.431 Val: 0.436 Test: 0.463 -- Best Val: 0.444 Test: 0.475\n",
            "631 20319.904 Train: 0.430 Val: 0.435 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "632 20303.455 Train: 0.432 Val: 0.438 Test: 0.464 -- Best Val: 0.444 Test: 0.475\n",
            "633 20324.918 Train: 0.430 Val: 0.435 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "634 20309.422 Train: 0.430 Val: 0.435 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "635 20329.426 Train: 0.431 Val: 0.438 Test: 0.463 -- Best Val: 0.444 Test: 0.475\n",
            "636 20318.05 Train: 0.430 Val: 0.435 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "637 20280.996 Train: 0.431 Val: 0.436 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "638 20278.56 Train: 0.431 Val: 0.438 Test: 0.466 -- Best Val: 0.444 Test: 0.475\n",
            "639 20309.338 Train: 0.431 Val: 0.435 Test: 0.464 -- Best Val: 0.444 Test: 0.475\n",
            "640 20295.16 Train: 0.430 Val: 0.435 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "641 20308.906 Train: 0.431 Val: 0.435 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "642 20267.527 Train: 0.431 Val: 0.435 Test: 0.463 -- Best Val: 0.444 Test: 0.475\n",
            "643 20293.91 Train: 0.430 Val: 0.435 Test: 0.463 -- Best Val: 0.444 Test: 0.475\n",
            "644 20281.82 Train: 0.430 Val: 0.435 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "645 20312.453 Train: 0.430 Val: 0.434 Test: 0.463 -- Best Val: 0.444 Test: 0.475\n",
            "646 20281.53 Train: 0.430 Val: 0.435 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "647 20295.143 Train: 0.429 Val: 0.434 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "648 20242.607 Train: 0.428 Val: 0.433 Test: 0.461 -- Best Val: 0.444 Test: 0.475\n",
            "649 20273.838 Train: 0.430 Val: 0.434 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "650 20263.26 Train: 0.430 Val: 0.434 Test: 0.461 -- Best Val: 0.444 Test: 0.475\n",
            "651 20283.072 Train: 0.429 Val: 0.434 Test: 0.460 -- Best Val: 0.444 Test: 0.475\n",
            "652 20279.807 Train: 0.430 Val: 0.434 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "653 20265.195 Train: 0.430 Val: 0.434 Test: 0.462 -- Best Val: 0.444 Test: 0.475\n",
            "654 20298.059 Train: 0.430 Val: 0.434 Test: 0.460 -- Best Val: 0.444 Test: 0.475\n",
            "655 20238.244 Train: 0.428 Val: 0.434 Test: 0.459 -- Best Val: 0.444 Test: 0.475\n",
            "656 20245.975 Train: 0.429 Val: 0.434 Test: 0.461 -- Best Val: 0.444 Test: 0.475\n",
            "657 20231.812 Train: 0.428 Val: 0.433 Test: 0.458 -- Best Val: 0.444 Test: 0.475\n",
            "658 20270.654 Train: 0.427 Val: 0.433 Test: 0.458 -- Best Val: 0.444 Test: 0.475\n",
            "659 20228.256 Train: 0.429 Val: 0.433 Test: 0.460 -- Best Val: 0.444 Test: 0.475\n",
            "660 20245.664 Train: 0.428 Val: 0.434 Test: 0.459 -- Best Val: 0.444 Test: 0.475\n",
            "661 20243.28 Train: 0.428 Val: 0.433 Test: 0.461 -- Best Val: 0.444 Test: 0.475\n",
            "662 20249.9 Train: 0.426 Val: 0.432 Test: 0.458 -- Best Val: 0.444 Test: 0.475\n",
            "663 20254.938 Train: 0.427 Val: 0.433 Test: 0.459 -- Best Val: 0.444 Test: 0.475\n",
            "664 20240.305 Train: 0.428 Val: 0.433 Test: 0.460 -- Best Val: 0.444 Test: 0.475\n",
            "665 20220.744 Train: 0.427 Val: 0.433 Test: 0.459 -- Best Val: 0.444 Test: 0.475\n",
            "666 20212.996 Train: 0.426 Val: 0.433 Test: 0.459 -- Best Val: 0.444 Test: 0.475\n",
            "667 20198.123 Train: 0.425 Val: 0.431 Test: 0.455 -- Best Val: 0.444 Test: 0.475\n",
            "668 20209.533 Train: 0.425 Val: 0.431 Test: 0.455 -- Best Val: 0.444 Test: 0.475\n",
            "669 20196.512 Train: 0.426 Val: 0.432 Test: 0.458 -- Best Val: 0.444 Test: 0.475\n",
            "670 20208.947 Train: 0.425 Val: 0.430 Test: 0.455 -- Best Val: 0.444 Test: 0.475\n",
            "671 20174.03 Train: 0.424 Val: 0.432 Test: 0.454 -- Best Val: 0.444 Test: 0.475\n",
            "672 20192.463 Train: 0.425 Val: 0.431 Test: 0.454 -- Best Val: 0.444 Test: 0.475\n",
            "673 20222.066 Train: 0.424 Val: 0.431 Test: 0.454 -- Best Val: 0.444 Test: 0.475\n",
            "674 20155.135 Train: 0.423 Val: 0.430 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "675 20147.424 Train: 0.425 Val: 0.431 Test: 0.455 -- Best Val: 0.444 Test: 0.475\n",
            "676 20170.17 Train: 0.422 Val: 0.429 Test: 0.453 -- Best Val: 0.444 Test: 0.475\n",
            "677 20167.479 Train: 0.425 Val: 0.431 Test: 0.455 -- Best Val: 0.444 Test: 0.475\n",
            "678 20189.113 Train: 0.423 Val: 0.430 Test: 0.453 -- Best Val: 0.444 Test: 0.475\n",
            "679 20164.045 Train: 0.422 Val: 0.428 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "680 20169.328 Train: 0.421 Val: 0.429 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "681 20170.98 Train: 0.424 Val: 0.430 Test: 0.453 -- Best Val: 0.444 Test: 0.475\n",
            "682 20133.654 Train: 0.423 Val: 0.429 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "683 20158.996 Train: 0.423 Val: 0.430 Test: 0.454 -- Best Val: 0.444 Test: 0.475\n",
            "684 20178.73 Train: 0.423 Val: 0.429 Test: 0.453 -- Best Val: 0.444 Test: 0.475\n",
            "685 20146.99 Train: 0.422 Val: 0.429 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "686 20135.803 Train: 0.422 Val: 0.429 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "687 20140.291 Train: 0.420 Val: 0.427 Test: 0.451 -- Best Val: 0.444 Test: 0.475\n",
            "688 20144.342 Train: 0.424 Val: 0.431 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "689 20114.676 Train: 0.423 Val: 0.429 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "690 20157.342 Train: 0.421 Val: 0.428 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "691 20140.385 Train: 0.421 Val: 0.427 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "692 20127.424 Train: 0.421 Val: 0.427 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "693 20140.89 Train: 0.422 Val: 0.428 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "694 20165.117 Train: 0.420 Val: 0.427 Test: 0.451 -- Best Val: 0.444 Test: 0.475\n",
            "695 20156.254 Train: 0.421 Val: 0.428 Test: 0.452 -- Best Val: 0.444 Test: 0.475\n",
            "696 20088.059 Train: 0.420 Val: 0.427 Test: 0.451 -- Best Val: 0.444 Test: 0.475\n",
            "697 20138.135 Train: 0.420 Val: 0.426 Test: 0.449 -- Best Val: 0.444 Test: 0.475\n",
            "698 20132.533 Train: 0.418 Val: 0.426 Test: 0.448 -- Best Val: 0.444 Test: 0.475\n",
            "699 20104.604 Train: 0.420 Val: 0.426 Test: 0.449 -- Best Val: 0.444 Test: 0.475\n",
            "700 20122.586 Train: 0.418 Val: 0.426 Test: 0.447 -- Best Val: 0.444 Test: 0.475\n",
            "701 20082.652 Train: 0.420 Val: 0.427 Test: 0.448 -- Best Val: 0.444 Test: 0.475\n",
            "702 20098.488 Train: 0.418 Val: 0.426 Test: 0.447 -- Best Val: 0.444 Test: 0.475\n",
            "703 20117.016 Train: 0.418 Val: 0.425 Test: 0.448 -- Best Val: 0.444 Test: 0.475\n",
            "704 20127.271 Train: 0.416 Val: 0.424 Test: 0.445 -- Best Val: 0.444 Test: 0.475\n",
            "705 20104.09 Train: 0.417 Val: 0.426 Test: 0.447 -- Best Val: 0.444 Test: 0.475\n",
            "706 20075.107 Train: 0.418 Val: 0.425 Test: 0.447 -- Best Val: 0.444 Test: 0.475\n",
            "707 20107.936 Train: 0.416 Val: 0.423 Test: 0.444 -- Best Val: 0.444 Test: 0.475\n",
            "708 20117.71 Train: 0.417 Val: 0.424 Test: 0.447 -- Best Val: 0.444 Test: 0.475\n",
            "709 20108.021 Train: 0.417 Val: 0.424 Test: 0.448 -- Best Val: 0.444 Test: 0.475\n",
            "710 20078.682 Train: 0.416 Val: 0.424 Test: 0.445 -- Best Val: 0.444 Test: 0.475\n",
            "711 20080.76 Train: 0.415 Val: 0.423 Test: 0.443 -- Best Val: 0.444 Test: 0.475\n",
            "712 20069.729 Train: 0.415 Val: 0.423 Test: 0.442 -- Best Val: 0.444 Test: 0.475\n",
            "713 20061.992 Train: 0.415 Val: 0.424 Test: 0.443 -- Best Val: 0.444 Test: 0.475\n",
            "714 20092.773 Train: 0.416 Val: 0.424 Test: 0.444 -- Best Val: 0.444 Test: 0.475\n",
            "715 20089.166 Train: 0.415 Val: 0.424 Test: 0.443 -- Best Val: 0.444 Test: 0.475\n",
            "716 20059.293 Train: 0.414 Val: 0.424 Test: 0.442 -- Best Val: 0.444 Test: 0.475\n",
            "717 20049.459 Train: 0.413 Val: 0.422 Test: 0.441 -- Best Val: 0.444 Test: 0.475\n",
            "718 20069.086 Train: 0.415 Val: 0.423 Test: 0.442 -- Best Val: 0.444 Test: 0.475\n",
            "719 20033.133 Train: 0.415 Val: 0.424 Test: 0.442 -- Best Val: 0.444 Test: 0.475\n",
            "720 20038.719 Train: 0.413 Val: 0.423 Test: 0.441 -- Best Val: 0.444 Test: 0.475\n",
            "721 20056.908 Train: 0.416 Val: 0.424 Test: 0.445 -- Best Val: 0.444 Test: 0.475\n",
            "722 20069.408 Train: 0.415 Val: 0.423 Test: 0.442 -- Best Val: 0.444 Test: 0.475\n",
            "723 20070.52 Train: 0.411 Val: 0.422 Test: 0.440 -- Best Val: 0.444 Test: 0.475\n",
            "724 20048.078 Train: 0.413 Val: 0.422 Test: 0.440 -- Best Val: 0.444 Test: 0.475\n",
            "725 20051.084 Train: 0.415 Val: 0.423 Test: 0.442 -- Best Val: 0.444 Test: 0.475\n",
            "726 20073.465 Train: 0.415 Val: 0.423 Test: 0.442 -- Best Val: 0.444 Test: 0.475\n",
            "727 20026.828 Train: 0.414 Val: 0.423 Test: 0.441 -- Best Val: 0.444 Test: 0.475\n",
            "728 20046.143 Train: 0.414 Val: 0.423 Test: 0.441 -- Best Val: 0.444 Test: 0.475\n",
            "729 20042.994 Train: 0.414 Val: 0.423 Test: 0.441 -- Best Val: 0.444 Test: 0.475\n",
            "730 20030.594 Train: 0.414 Val: 0.423 Test: 0.441 -- Best Val: 0.444 Test: 0.475\n",
            "731 20059.709 Train: 0.414 Val: 0.423 Test: 0.441 -- Best Val: 0.444 Test: 0.475\n",
            "732 20038.572 Train: 0.414 Val: 0.423 Test: 0.441 -- Best Val: 0.444 Test: 0.475\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-208-478212e843f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mxbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmax_length_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mybatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mybatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mypred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-B4QrYhOy9u"
      },
      "source": [
        ""
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDwot8oPMYpT",
        "outputId": "8a535670-9356-4b82-a919-250f87832d00"
      },
      "source": [
        "print_sentence_pred_label(xtest[1], ypred[1], ytest[1])"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "editor author \t\t in\n",
            "editor author \t\t bouma\n",
            "editor author \t\t ,\n",
            "editor author \t\t h\n",
            "editor author \t\t .\n",
            "editor author \t\t ,\n",
            "editor author \t\t &\n",
            "editor title \t\t elsendoorn\n",
            "editor author \t\t ,\n",
            "editor title \t\t a\n",
            "editor title \t\t .\n",
            "editor title \t\t g\n",
            "editor title \t\t .\n",
            "editor title \t\t (\n",
            "editor title \t\t eds\n",
            "editor title \t\t .\n",
            "editor title \t\t )\n",
            "editor title \t\t ,\n",
            "title title \t\t working\n",
            "title title \t\t models\n",
            "title title \t\t of\n",
            "title title \t\t human\n",
            "title title \t\t perception\n",
            "title title \t\t ,\n",
            "pages title \t\t pp\n",
            "pages title \t\t .\n",
            "pages title \t\t 391\n",
            "pages title \t\t -\n",
            "pages title \t\t 410\n",
            "pages title \t\t .\n",
            "publisher title \t\t academic\n",
            "publisher title \t\t press\n",
            "publisher title \t\t ,\n",
            "location title \t\t london\n",
            "location title \t\t ,\n",
            "location PAD \t\t england\n",
            "location PAD \t\t .\n"
          ]
        }
      ]
    }
  ]
}